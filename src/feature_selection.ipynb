{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97e5222a",
   "metadata": {},
   "source": [
    "# Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79c84ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# xgboost\n",
    "from sklearn import metrics\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# PCA\n",
    "from factor_analyzer.factor_analyzer import calculate_bartlett_sphericity\n",
    "from factor_analyzer.factor_analyzer import calculate_kmo\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "from sklearn.decomposition import PCA\n",
    "from kneed import KneeLocator\n",
    "\n",
    "# logreg / rfe\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# to display all rows in dataframes\n",
    "pd.set_option('display.max_rows', None) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00ac2f6",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64ea3f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/grouped_data.csv\")\n",
    "X_train = pd.read_csv(\"../data/X_train_final.csv\")\n",
    "X_test = pd.read_csv(\"../data/X_test_final.csv\")\n",
    "y_train = pd.read_csv(\"../data/y_train_final.csv\")\n",
    "y_test = pd.read_csv(\"../data/y_test_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf6df51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode the categories\n",
    "features_nominal = ['order_1', 'order_2', 'order_3', 'order_6', 'order_7']\n",
    "X_train = pd.get_dummies(X_train, columns = features_nominal)\n",
    "X_test = pd.get_dummies(X_test, columns = features_nominal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85babeaf",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "157f875e",
   "metadata": {},
   "outputs": [],
   "source": [
    "impt_feat = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab85de68",
   "metadata": {},
   "source": [
    "## XGB feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb9499b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    }
   ],
   "source": [
    "# fit model to training data\n",
    "xgb = XGBClassifier(eval_metric = ['logloss'], use_label_encoder=False)\n",
    "xgb.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "feats = {} # a dict to hold feature_name: feature_importance\n",
    "for feature, importance in zip(X_train.columns, xgb.feature_importances_):\n",
    "    feats[feature] = importance #add the name/value pair \n",
    "\n",
    "importances = pd.DataFrame(feats.items(), columns=['Feature', 'Importance'])\n",
    "#.rename(columns={0: 'importance'})\n",
    "importances = importances.sort_values(by = ['Importance'], ascending = False)\n",
    "impt_feat.extend(importances.Feature.iloc[0:30].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31a3ce5",
   "metadata": {},
   "source": [
    "## PCA dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fc7fab",
   "metadata": {},
   "source": [
    "Remove categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ffe5de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca = df.drop(columns = ['label', 'sevenmers', 'gene_id', 'transcript_id', 'order_1', 'order_2', 'order_3', 'order_6', 'order_7'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be14e309",
   "metadata": {},
   "outputs": [],
   "source": [
    "fa = FactorAnalyzer(n_factors = 10, method = 'principal', rotation='varimax')\n",
    "fa.fit(df_pca)\n",
    "eigenvalues, _ = fa.get_eigenvalues()\n",
    "variances = fa.get_factor_variance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6d29ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pcs(num_of_pcs,data):\n",
    "    def encode_vals(x):\n",
    "        if x <= -0.7 or x >= 0.7:\n",
    "            return x\n",
    "        else:\n",
    "            return(\"\")    \n",
    "    # REMARK: we use 'principal' method and 'varimax' rotation in the FactorAnalyzer function.\n",
    "    f = FactorAnalyzer(n_factors=num_of_pcs, method = 'principal',rotation='varimax')\n",
    "    f.fit(data)\n",
    "    loadings = pd.DataFrame(f.loadings_).set_index(data.columns)\n",
    "    loadings = loadings.applymap(encode_vals)\n",
    "    loadingcols= list(loadings.columns)\n",
    "    newcols = {}\n",
    "    for i in loadingcols:\n",
    "        newcols[i] = \"PC\" + str(i+1)\n",
    "    loadings.rename(columns = newcols,inplace=True)\n",
    "    return loadings\n",
    "\n",
    "# The following function generates the rotation matrix. Recall that we use\n",
    "# this matrix to determine if the PCs generated are easily understandable and appropriate.\n",
    "# The argument \"num_of_pcs\" specifies, the number of PCs we wish to generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cff14ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_df = evaluate_pcs(9,df_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3566c4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "value = []\n",
    "which = lambda lst:list(np.where(lst)[0])\n",
    "for i in PCA_df.columns:\n",
    "    value.extend(which(PCA_df[i] == ''))\n",
    "    \n",
    "value = pd.DataFrame(value).rename(columns = {0: 'rowno'})\n",
    "val_counts = pd.DataFrame(value.value_counts()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af9d57b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "drop_cols = val_counts[val_counts[0] == 9]['rowno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94db3949",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_df = df.drop(columns = list(PCA_df.index[drop_cols]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5b1d934",
   "metadata": {},
   "outputs": [],
   "source": [
    "impt_feat.extend(keep_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8086c6",
   "metadata": {},
   "source": [
    "## RFE Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22600ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7dbfd419",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe3 = RFE(logreg, n_features_to_select=30)\n",
    "rfe3 = rfe3.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00ecdf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols remaining\n",
    "cols_keep = X_train.columns.values[rfe3.support_]\n",
    "impt_feat.extend(cols_keep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2f86db",
   "metadata": {},
   "source": [
    "## Feature Importance using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7726355d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_jobs=-1, random_state=1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline model with default parameters\n",
    "forest1 = RandomForestClassifier(random_state = 1, n_jobs= -1)\n",
    "forest1.fit(X_train,y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8cd61128",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = {} # a dict to hold feature_name: feature_importance\n",
    "for feature, importance in zip(X_train.columns, forest1.feature_importances_):\n",
    "    feats[feature] = importance #add the name/value pair \n",
    "\n",
    "importances = pd.DataFrame(feats.items(), columns=['Feature', 'Importance'])\n",
    "#.rename(columns={0: 'importance'})\n",
    "importances = importances.sort_values(by = ['Importance'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "693848ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "impt_feat.extend(importances.Feature.iloc[0: 30].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0f39e2",
   "metadata": {},
   "source": [
    "# Check the Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14381267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select feature counts >= 2\n",
    "features = pd.DataFrame(impt_feat).rename(columns = {0: 'feat'})\n",
    "feature_count = pd.DataFrame(features.value_counts()).reset_index()\n",
    "impt_feat = feature_count[feature_count[0] >= 2]['feat']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e5153a",
   "metadata": {},
   "source": [
    "# Remove Collinear Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4015f75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/29294983/how-to-calculate-correlation-between-all-columns-and-remove-highly-correlated-on\n",
    "def remove_collinear_features(df_model, target_var, threshold, verbose, final_features):\n",
    "    '''\n",
    "    Objective:\n",
    "        Remove collinear features in a dataframe with a correlation coefficient\n",
    "        greater than the threshold and which have the least correlation with the target (dependent) variable. Removing collinear features can help a model \n",
    "        to generalize and improves the interpretability of the model.\n",
    "\n",
    "    Inputs: \n",
    "        df_model: features dataframe\n",
    "        target_var: target (dependent) variable\n",
    "        threshold: features with correlations greater than this value are removed\n",
    "        verbose: set to \"True\" for the log printing\n",
    "\n",
    "    Output: \n",
    "        dataframe that contains only the non-highly-collinear features\n",
    "    '''\n",
    "\n",
    "    # Calculate the correlation matrix\n",
    "    corr_matrix = df_model.drop(target_var, 1).corr()\n",
    "    iters = range(len(corr_matrix.columns) - 1)\n",
    "    drop_cols = []\n",
    "    dropped_feature = \"\"\n",
    "\n",
    "    # Iterate through the correlation matrix and compare correlations\n",
    "    for i in iters:\n",
    "        for j in range(i+1): \n",
    "            item = corr_matrix.iloc[j:(j+1), (i+1):(i+2)]\n",
    "            col = item.columns\n",
    "            row = item.index\n",
    "            val = abs(item.values)\n",
    "\n",
    "            # If correlation exceeds the threshold\n",
    "            if val >= threshold:\n",
    "                # Print the correlated features and the correlation value\n",
    "                if verbose:\n",
    "                    print(col.values[0], \"|\", row.values[0], \"|\", round(val[0][0], 2))\n",
    "                col_value_corr = df_model[col.values[0]].corr(df_model[target_var])\n",
    "                row_value_corr = df_model[row.values[0]].corr(df_model[target_var])\n",
    "                if verbose:\n",
    "                    print(\"{}: {}\".format(col.values[0], np.round(col_value_corr, 3)))\n",
    "                    print(\"{}: {}\".format(row.values[0], np.round(row_value_corr, 3)))\n",
    "                if col_value_corr < row_value_corr:\n",
    "                    drop_cols.append(col.values[0])\n",
    "                    dropped_feature = \"dropped: \" + col.values[0]\n",
    "                else:\n",
    "                    drop_cols.append(row.values[0])\n",
    "                    dropped_feature = \"dropped: \" + row.values[0]\n",
    "                if verbose:\n",
    "                    print(dropped_feature)\n",
    "                    print(\"-----------------------------------------------------------------------------\")\n",
    "\n",
    "    # Drop one of each pair of correlated columns\n",
    "    drops = set(drop_cols)\n",
    "    df_model = df_model.drop(columns=drops)\n",
    "\n",
    "    #print(\"dropped columns: \")\n",
    "    #print(list(drops))\n",
    "    #print(\"-----------------------------------------------------------------------------\")\n",
    "    #print(\"final columns: \")\n",
    "    #print(df_model.columns.tolist())\n",
    "    final_features = final_features.extend(df_model.columns.tolist())\n",
    "\n",
    "    #return df_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e708e865",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sg/256rs4d52q1fcb1g9mh332jc0000gn/T/ipykernel_67830/2253806852.py:20: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  corr_matrix = df_model.drop(target_var, 1).corr()\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train[impt_feat]\n",
    "df = pd.concat([X_train, y_train], axis=1)\n",
    "final_features = []\n",
    "remove_collinear_features(df, 'label', 0.9, False, final_features)\n",
    "final_features.remove('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5aca8d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mean_current_3_median',\n",
       " 'sd_current_2_std',\n",
       " 'mean_current_1_median',\n",
       " 'mean_current_1_min',\n",
       " 'mean_current_1_std',\n",
       " 'mean_current_2_std',\n",
       " 'count_G',\n",
       " 'mean_current_3_min',\n",
       " 'diff_sd_current_1_std',\n",
       " 'mean_current_3_std',\n",
       " 'order_6_T',\n",
       " 'sd_current_2_min',\n",
       " 'sd_current_3_median',\n",
       " 'diff_sd_current_2_std',\n",
       " 'diff_mean_current_2_std',\n",
       " 'mean_current_3_max',\n",
       " 'relative_position',\n",
       " 'mean_current_2_max',\n",
       " 'diff_mean_current_1_min',\n",
       " 'sd_current_2_max',\n",
       " 'sd_current_1_median',\n",
       " 'dwelling_time_3_max',\n",
       " 'diff_sd_current_2_median',\n",
       " 'sd_current_3_max',\n",
       " 'sd_current_3_std',\n",
       " 'order_2_G',\n",
       " 'diff_sd_current_1_median']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6227ee44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
