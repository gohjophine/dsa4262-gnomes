{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97e5222a",
   "metadata": {},
   "source": [
    "# Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79c84ae5",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (xgboost.py, line 43)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"C:\\Users\\Yueh Leng\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m3437\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-aebc161fbd55>\"\u001b[1;36m, line \u001b[1;32m9\u001b[1;36m, in \u001b[1;35m<module>\u001b[1;36m\u001b[0m\n\u001b[1;33m    from xgboost import XGBClassifier\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Yueh Leng\\Downloads\\xgboost.py\"\u001b[1;36m, line \u001b[1;32m43\u001b[0m\n\u001b[1;33m    !pip install xgboost==0.90\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# xgboost\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# PCA\n",
    "from factor_analyzer.factor_analyzer import calculate_bartlett_sphericity\n",
    "from factor_analyzer.factor_analyzer import calculate_kmo\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "from sklearn.decomposition import PCA\n",
    "from kneed import KneeLocator\n",
    "\n",
    "# logreg / rfe\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# to display all rows in dataframes\n",
    "pd.set_option('display.max_rows', None) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00ac2f6",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ea3f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/grouped_data.csv\")\n",
    "X_train = pd.read_csv(\"../data/X_train_final.csv\")\n",
    "X_test = pd.read_csv(\"../data/X_test_final.csv\")\n",
    "y_train = pd.read_csv(\"../data/y_train_final.csv\")\n",
    "y_test = pd.read_csv(\"../data/y_test_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6df51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode the categories\n",
    "features_nominal = ['order_1', 'order_2', 'order_3', 'order_6', 'order_7']\n",
    "X_train = pd.get_dummies(X_train, columns = features_nominal)\n",
    "X_test = pd.get_dummies(X_test, columns = features_nominal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85babeaf",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157f875e",
   "metadata": {},
   "outputs": [],
   "source": [
    "impt_feat = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab85de68",
   "metadata": {},
   "source": [
    "## XGB feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9499b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model to training data\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "feats = {} # a dict to hold feature_name: feature_importance\n",
    "for feature, importance in zip(X_train.columns, xgb.feature_importances_):\n",
    "    feats[feature] = importance #add the name/value pair \n",
    "\n",
    "importances = pd.DataFrame(feats.items(), columns=['Feature', 'Importance'])\n",
    "#.rename(columns={0: 'importance'})\n",
    "importances = importances.sort_values(by = ['Importance'], ascending = False)\n",
    "impt_feat.extend(importances.Feature.iloc[0:30].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01a0883",
   "metadata": {},
   "outputs": [],
   "source": [
    "impt_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31a3ce5",
   "metadata": {},
   "source": [
    "## PCA dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fc7fab",
   "metadata": {},
   "source": [
    "Remove categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffe5de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca = df.drop(columns = ['label', 'sevenmers', 'gene_id', 'transcript_id', 'order_1', 'order_2', 'order_3', 'order_6', 'order_7'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd1e9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ , p_value = calculate_bartlett_sphericity(df_pca)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a926023e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, kmo_score = calculate_kmo(df_pca)\n",
    "kmo_score "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe05978d",
   "metadata": {},
   "source": [
    "As p-value < 0.5 and kmo score > 0.5, PCA is suitable on the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be14e309",
   "metadata": {},
   "outputs": [],
   "source": [
    "fa = FactorAnalyzer(n_factors = 10, method = 'principal', rotation='varimax')\n",
    "fa.fit(df_pca)\n",
    "eigenvalues, _ = fa.get_eigenvalues()\n",
    "variances = fa.get_factor_variance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0077ccca",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(range(1,11))\n",
    "plt.figure(figsize=(10, 7)) \n",
    "plt.bar(x,variances[2])\n",
    "plt.title('Cumulative Variance')\n",
    "plt.xlabel('PC Number')\n",
    "plt.ylabel('Proportion of Variance Explained by PC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d29ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pcs(num_of_pcs,data):\n",
    "    def encode_vals(x):\n",
    "        if x <= -0.7 or x >= 0.7:\n",
    "            return x\n",
    "        else:\n",
    "            return(\"\")    \n",
    "    # REMARK: we use 'principal' method and 'varimax' rotation in the FactorAnalyzer function.\n",
    "    f = FactorAnalyzer(n_factors=num_of_pcs, method = 'principal',rotation='varimax')\n",
    "    f.fit(data)\n",
    "    loadings = pd.DataFrame(f.loadings_).set_index(data.columns)\n",
    "    loadings = loadings.applymap(encode_vals)\n",
    "    loadingcols= list(loadings.columns)\n",
    "    newcols = {}\n",
    "    for i in loadingcols:\n",
    "        newcols[i] = \"PC\" + str(i+1)\n",
    "    loadings.rename(columns = newcols,inplace=True)\n",
    "    return loadings\n",
    "\n",
    "# The following function generates the rotation matrix. Recall that we use\n",
    "# this matrix to determine if the PCs generated are easily understandable and appropriate.\n",
    "# The argument \"num_of_pcs\" specifies, the number of PCs we wish to generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5868c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_explained(num_of_pcs,data):\n",
    "    # REMARK: we use 'principal' method and 'varimax' rotation in the FactorAnalyzer function.\n",
    "    f = FactorAnalyzer(n_factors=num_of_pcs, method = 'principal',rotation='varimax')\n",
    "    f.fit(data)\n",
    "    return f.get_factor_variance()[2][num_of_pcs-1]\n",
    "\n",
    "# The following function calculates the variance explained by the specified desired number of PCs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33429dd",
   "metadata": {},
   "source": [
    "Chose 9 PCs as it explains >70% of the variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae9a8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_explained(9, df_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff14ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_pcs(9,df_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33635a0",
   "metadata": {},
   "source": [
    "Drop the columns that are not in any PCs as they are not as important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5aa99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.drop(columns = ['transcript_position', 'dwelling_time_1_min',\n",
    "                           'sd_current_1_min', 'sd_current_1_max', 'sd_current_1_std',\n",
    "                           'mean_current_1_std', 'dwelling_time_2_min', 'dwelling_time_2_median',\n",
    "                           'sd_current_2_min', 'mean_current_2_min', 'mean_current_2_max', 'mean_current_2_median',\n",
    "                           'mean_current_2_std', 'dwelling_time_3_min', 'sd_current_3_min',\n",
    "                           'mean_current_3_std', 'diff_dwelling_time_1_median', 'diff_dwelling_time_1_std',\n",
    "                           'diff_dwelling_time_2_median', 'diff_sd_current_1_min', 'diff_sd_current_1_median',\n",
    "                           'diff_mean_current_1_max', 'diff_mean_current_1_std', 'diff_mean_current_2_min',\n",
    "                           'diff_mean_current_2_median', 'relative_position', 'count_A', 'count_C', 'count_G', 'count_T'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b1d934",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols2keep_pca = new_df.columns\n",
    "impt_feat.extend(new_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8086c6",
   "metadata": {},
   "source": [
    "## RFE Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1156ef1b",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22600ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbfd419",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe3 = RFE(logreg, n_features_to_select=30)\n",
    "rfe3 = rfe3.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046e1430",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ecdf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols remaining\n",
    "cols_keep = X_train.columns.values[rfe3.support_]\n",
    "impt_feat.extend(cols_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aa46a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "impt_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730eda3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(impt_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2f86db",
   "metadata": {},
   "source": [
    "## Feature Importance using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7726355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model with default parameters\n",
    "start = time.time()\n",
    "forest1 = RandomForestClassifier(random_state = 1, n_jobs= -1)\n",
    "forest1.fit(X_train,y_train.values.ravel())\n",
    "end = time.time()\n",
    "print(\"Time taken:\", (end-start)/60, \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891910d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_y_pred = forest1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec7bb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.confusion_matrix(y_test, rf_y_pred))\n",
    "# TN FP\n",
    "# FN TP\n",
    "\n",
    "print(f'accuracy: {metrics.accuracy_score(y_test, rf_y_pred)}')\n",
    "print(f'precision: {metrics.precision_score(y_test,rf_y_pred)}')\n",
    "print(f'recall:    {metrics.recall_score(y_test, rf_y_pred)}')\n",
    "print(f'roc auc:   {metrics.roc_auc_score(y_test, rf_y_pred)}')\n",
    "print(f'pr auc:    {metrics.average_precision_score(y_test, rf_y_pred)}')\n",
    "\n",
    "y_predict_prob = forest1.predict_proba(X_test)[:, 1]\n",
    "print(metrics.confusion_matrix(y_test, rf_y_pred))\n",
    "print(f'roc auc:   {metrics.roc_auc_score(y_test, y_predict_prob)}')\n",
    "print(f'pr auc:    {metrics.average_precision_score(y_test, y_predict_prob)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a4d9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = forest1.feature_importances_\n",
    "importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd61128",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = {} # a dict to hold feature_name: feature_importance\n",
    "for feature, importance in zip(X_train.columns, forest1.feature_importances_):\n",
    "    feats[feature] = importance #add the name/value pair \n",
    "\n",
    "importances = pd.DataFrame(feats.items(), columns=['Feature', 'Importance'])\n",
    "#.rename(columns={0: 'importance'})\n",
    "importances = importances.sort_values(by = ['Importance'], ascending = False)\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c8ed3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances.Feature.iloc[0: 40].tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "ca66b8394c3a02d89528c1875dd918765588c212302cd33a443773560b855c54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
