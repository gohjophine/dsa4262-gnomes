{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ead5e974",
   "metadata": {},
   "source": [
    "# Resampling (grouped_data.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56f4c116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GroupShuffleSplit \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb8bb13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '../data/grouped_data.csv'\n",
    "# input_path = '../data/grouped_data1.csv'\n",
    "# input_path = '../data/grouped_data2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4758da4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing this part as we will be using the whole dataset for training\n",
    "# # split dataset into X y train test, based on gene_id\n",
    "# # input: df, split_size\n",
    "# # output: train df, test df\n",
    "# def split(df, split_size=0.2):\n",
    "#     splitter = GroupShuffleSplit(test_size=split_size, n_splits=1, random_state=42)\n",
    "#     split = splitter.split(df, groups=df['gene_id'])\n",
    "#     train_inds, test_inds = next(split)\n",
    "#     train = df.iloc[train_inds]\n",
    "#     test = df.iloc[test_inds]\n",
    "    \n",
    "#     y_train = train['label']\n",
    "#     X_train = train.drop(['label', 'sevenmers'], axis = 1)\n",
    "#     y_test = test['label']\n",
    "#     X_test = test.drop(['label', 'sevenmers'], axis = 1)\n",
    "    \n",
    "#     return X_train, y_train, X_test, y_test\n",
    "\n",
    "# oversample and undersample such that ratio of minority to majority samples becomes 3:4\n",
    "# input: df, df (X_train, y_train)\n",
    "# output: df, df (resampled version)\n",
    "def resample(X_train, y_train):\n",
    "    # define oversampling strategy so that ratio of minority samples to majority samples is 1:2\n",
    "    oversample = RandomOverSampler(sampling_strategy=0.5, random_state=42)\n",
    "    X_train_over, y_train_over = oversample.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # define undersampling strategy so that the ratio of minority to majority samples becomes 3:4\n",
    "    under = RandomUnderSampler(sampling_strategy=0.75)\n",
    "    X_train_under, y_train_under = under.fit_resample(X_train_over, y_train_over)\n",
    "    return X_train_under, y_train_under\n",
    "\n",
    "df = pd.read_csv(input_path)\n",
    "features_nominal = ['order_1', 'order_2', 'order_3', 'order_6', 'order_7']\n",
    "df[features_nominal] = df[features_nominal].astype('category')\n",
    "\n",
    "if (input_path == '../data/grouped_data.csv'):\n",
    "    # X_train, y_train, X_test, y_test = split(df)\n",
    "    y_train = df['label']\n",
    "    X_train = df.drop(['label', 'sevenmers'], axis = 1)\n",
    "    X_train, y_train = resample(X_train, y_train)\n",
    "    X_train = X_train.drop(columns=['gene_id', 'transcript_id'])\n",
    "    # X_test = X_test.drop(columns=['gene_id', 'transcript_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f52abb",
   "metadata": {},
   "source": [
    "# Normalisation (all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d807ec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise the numerical columns\n",
    "# input: df\n",
    "# output: normalised df\n",
    "def normalise(df):\n",
    "    numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    string_columns = df.select_dtypes(include=['object', 'category']).columns\n",
    "    \n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(df[numerical_columns])\n",
    "    \n",
    "    df_normalised = pd.DataFrame(x_scaled)\n",
    "    df_normalised.columns = numerical_columns\n",
    "    \n",
    "    final_df = pd.concat([df[string_columns].reset_index(), df_normalised], axis=1)\n",
    "    final_df = final_df.drop(columns = ['index'])\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df00c78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if it's the train data, normalise after splitting\n",
    "if (input_path == '../data/grouped_data.csv'):\n",
    "    X_train_norm = normalise(X_train)\n",
    "    # X_test_norm = normalise(X_test)\n",
    "else:\n",
    "    df_norm = normalise(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9c677c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print column name if there's null values in df\n",
    "def check(df):\n",
    "    for name in df.columns:\n",
    "        if (df[name].isnull().any()):\n",
    "            print(name)\n",
    "\n",
    "if (input_path == '../data/grouped_data.csv'):\n",
    "    check(X_train_norm)\n",
    "    # check(X_test_norm)\n",
    "else:\n",
    "    check(df_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c0d59b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise for dataset 0 \n",
    "df_norm_d0 = normalise(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1fdeae05",
   "metadata": {},
   "outputs": [],
   "source": [
    "check(df_norm_d0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bcb77e",
   "metadata": {},
   "source": [
    "# Export to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "281272a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (input_path == '../data/grouped_data.csv'):\n",
    "    X_train_norm.to_csv('../data/X_train_final.csv', index=False)\n",
    "    # X_test_norm.to_csv('../data/X_test_final.csv', index=False)\n",
    "    y_train.to_csv('../data/y_train_final.csv', index=False)\n",
    "    # y_test.to_csv('../data/y_test_final.csv', index=False)\n",
    "\n",
    "elif (input_path == '../data/grouped_data1.csv'):\n",
    "    df_norm.to_csv('../data/final_data1.csv', index=False)\n",
    "    \n",
    "else:\n",
    "    df_norm.to_csv('../data/final_data2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53f38c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm_d0.to_csv('../data/final_data0.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
